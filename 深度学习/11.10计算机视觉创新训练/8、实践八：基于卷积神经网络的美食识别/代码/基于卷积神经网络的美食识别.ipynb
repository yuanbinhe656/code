{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 任务描述：\n",
    "\n",
    "### 如何根据据图像的视觉内容为图像赋予一个语义类别是**图像分类**的目标，也是图像检索、图像内容分析和目标识别等问题的基础。\n",
    "\n",
    "### 本实践旨在通过一个美食分类的案列，让大家理解和掌握如何使用飞桨动态图搭建一个**卷积神经网络**。\n",
    "\n",
    "### 特别提示：本实践所用数据集均来自互联网，请勿用于商务用途。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import json\n",
    "import paddle\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import paddle\n",
    "from paddle import fluid\n",
    "import matplotlib.pyplot as plt \n",
    "import paddle.vision.transforms as T  \n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "参数配置\n",
    "'''\n",
    "train_parameters = {\n",
    "    \"input_size\": [3, 64, 64],                                #输入图片的shape\n",
    "    \"class_dim\": 5,                                          #分类数\n",
    "    \"src_path\":\"data/data42610/foods.zip\",                    #原始数据集路径\n",
    "    \"target_path\":\"/home/aistudio/data/\",                     #要解压的路径\n",
    "    \"train_list_path\": \"/home/aistudio/data/train.txt\",       #train.txt路径\n",
    "    \"eval_list_path\": \"/home/aistudio/data/eval.txt\",         #eval.txt路径\n",
    "    \"readme_path\": \"/home/aistudio/data/readme.json\",         #readme.json路径\n",
    "    \"label_dict\":{},                                          #标签字典\n",
    "    \"num_epochs\": 2,                                          #训练轮数\n",
    "    \"train_batch_size\": 64,                                   #训练时每个批次的大小\n",
    "    \"learning_strategy\": {                                    #优化函数相关的配置\n",
    "        \"lr\": 0.01                                          #超参数学习率\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n"
     ]
    }
   ],
   "source": [
    "print(paddle.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **一、数据准备**\n",
    "\n",
    "### （1）解压原始数据集\n",
    "\n",
    "### （2）按照比例划分训练集与验证集\n",
    "\n",
    "### （3）乱序，生成数据列表\n",
    "\n",
    "### （4）构造训练数据集提供器和验证数据集提供器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def unzip_data(src_path,target_path):\n",
    "    '''\n",
    "    解压原始数据集，将src_path路径下的zip包解压至target_path目录下\n",
    "    '''\n",
    "    if(not os.path.isdir(target_path + \"foods\")):     \n",
    "        z = zipfile.ZipFile(src_path, 'r')\n",
    "        z.extractall(path=target_path)\n",
    "        z.close()\n",
    "\n",
    "def get_data_list(target_path,train_list_path,eval_list_path):\n",
    "    '''\n",
    "    生成数据列表\n",
    "    '''\n",
    "    #存放所有类别的信息\n",
    "    class_detail = []\n",
    "    #获取所有类别保存的文件夹名称\n",
    "    data_list_path=target_path+\"foods/\"\n",
    "    class_dirs = os.listdir(data_list_path)  \n",
    "    #总的图像数量\n",
    "    all_class_images = 0\n",
    "    #存放类别标签\n",
    "    class_label=0\n",
    "    #存放类别数目\n",
    "    class_dim = 0\n",
    "    #存储要写进eval.txt和train.txt中的内容\n",
    "    trainer_list=[]\n",
    "    eval_list=[]\n",
    "    #读取每个类别\n",
    "    for class_dir in class_dirs:\n",
    "        if class_dir != \".DS_Store\":\n",
    "            class_dim += 1\n",
    "            #每个类别的信息\n",
    "            class_detail_list = {}\n",
    "            eval_sum = 0\n",
    "            trainer_sum = 0\n",
    "            #统计每个类别有多少张图片\n",
    "            class_sum = 0\n",
    "            #获取类别路径 \n",
    "            path = data_list_path  + class_dir\n",
    "            # 获取所有图片\n",
    "            img_paths = os.listdir(path)\n",
    "            for img_path in img_paths:                                  # 遍历文件夹下的每个图片\n",
    "                name_path = path + '/' + img_path                       # 每张图片的路径\n",
    "                if class_sum % 10 == 0:                                  # 每10张图片取一个做验证数据\n",
    "                    eval_sum += 1                                       # test_sum为测试数据的数目\n",
    "                    eval_list.append(name_path + \"\\t%d\" % class_label + \"\\n\")\n",
    "                else:\n",
    "                    trainer_sum += 1 \n",
    "                    trainer_list.append(name_path + \"\\t%d\" % class_label + \"\\n\")#trainer_sum测试数据的数目\n",
    "                class_sum += 1                                          #每类图片的数目\n",
    "                all_class_images += 1                                   #所有类图片的数目\n",
    "             \n",
    "            # 说明的json文件的class_detail数据\n",
    "            class_detail_list['class_name'] = class_dir             #类别名称\n",
    "            class_detail_list['class_label'] = class_label          #类别标签\n",
    "            class_detail_list['class_eval_images'] = eval_sum       #该类数据的测试集数目\n",
    "            class_detail_list['class_trainer_images'] = trainer_sum #该类数据的训练集数目\n",
    "            class_detail.append(class_detail_list)  \n",
    "            #初始化标签列表\n",
    "            train_parameters['label_dict'][str(class_label)] = class_dir\n",
    "            class_label += 1 \n",
    "            \n",
    "    #初始化分类数\n",
    "    train_parameters['class_dim'] = class_dim\n",
    "    \n",
    "    #乱序  \n",
    "    random.shuffle(eval_list)\n",
    "    with open(eval_list_path, 'a') as f:\n",
    "        for eval_image in eval_list:\n",
    "            f.write(eval_image) \n",
    "            \n",
    "    random.shuffle(trainer_list)\n",
    "    with open(train_list_path, 'a') as f2:\n",
    "        for train_image in trainer_list:\n",
    "            f2.write(train_image) \n",
    "\n",
    "    # 说明的json文件信息\n",
    "    readjson = {}\n",
    "    readjson['all_class_name'] = data_list_path                  #文件父目录\n",
    "    readjson['all_class_images'] = all_class_images\n",
    "    readjson['class_detail'] = class_detail\n",
    "    jsons = json.dumps(readjson, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "    with open(train_parameters['readme_path'],'w') as f:\n",
    "        f.write(jsons)\n",
    "    print ('生成数据列表完成！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成数据列表完成！\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "参数初始化\n",
    "'''\n",
    "src_path=train_parameters['src_path']\n",
    "target_path=train_parameters['target_path']\n",
    "train_list_path=train_parameters['train_list_path']\n",
    "eval_list_path=train_parameters['eval_list_path']\n",
    "batch_size=train_parameters['train_batch_size']\n",
    "\n",
    "'''\n",
    "解压原始数据到指定路径\n",
    "'''\n",
    "unzip_data(src_path,target_path)\n",
    "\n",
    "'''\n",
    "划分训练集与验证集，乱序，生成数据列表\n",
    "'''\n",
    "#每次生成数据列表前，首先清空train.txt和eval.txt\n",
    "with open(train_list_path, 'w') as f: \n",
    "    f.seek(0)\n",
    "    f.truncate() \n",
    "with open(eval_list_path, 'w') as f: \n",
    "    f.seek(0)\n",
    "    f.truncate() \n",
    "    \n",
    "#生成数据列表   \n",
    "get_data_list(target_path,train_list_path,eval_list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "class FoodDataset(paddle.io.Dataset):\r\n",
    "    def __init__(self, data_path, mode='train'):\r\n",
    "        \"\"\"\r\n",
    "        数据读取器\r\n",
    "        :param data_path: 数据集所在路径\r\n",
    "        :param mode: train or eval\r\n",
    "        \"\"\"\r\n",
    "        super().__init__()\r\n",
    "        self.data_path = data_path\r\n",
    "        self.img_paths = []\r\n",
    "        self.labels = []\r\n",
    "\r\n",
    "        if mode == 'train':\r\n",
    "            with open(os.path.join(self.data_path, \"train.txt\"), \"r\", encoding=\"utf-8\") as f:\r\n",
    "                self.info = f.readlines()\r\n",
    "            for img_info in self.info:\r\n",
    "                img_path, label = img_info.strip().split('\\t')\r\n",
    "                self.img_paths.append(img_path)\r\n",
    "                self.labels.append(int(label))\r\n",
    "\r\n",
    "        else:\r\n",
    "            with open(os.path.join(self.data_path, \"eval.txt\"), \"r\", encoding=\"utf-8\") as f:\r\n",
    "                self.info = f.readlines()\r\n",
    "            for img_info in self.info:\r\n",
    "                img_path, label = img_info.strip().split('\\t')\r\n",
    "                self.img_paths.append(img_path)\r\n",
    "                self.labels.append(int(label))\r\n",
    "\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        \"\"\"\r\n",
    "        获取一组数据\r\n",
    "        :param index: 文件索引号\r\n",
    "        :return:\r\n",
    "        \"\"\"\r\n",
    "        # 第一步打开图像文件并获取label值\r\n",
    "        img_path = self.img_paths[index]\r\n",
    "        img = Image.open(img_path)\r\n",
    "        if img.mode != 'RGB':\r\n",
    "            img = img.convert('RGB') \r\n",
    "        img = img.resize((64, 64), Image.BILINEAR)\r\n",
    "        img = np.array(img).astype('float32')\r\n",
    "        img = img.transpose((2, 0, 1)) / 255\r\n",
    "        label = self.labels[index]\r\n",
    "        label = np.array([label], dtype=\"int64\")\r\n",
    "        return img, label\r\n",
    "\r\n",
    "    def print_sample(self, index: int = 0):\r\n",
    "        print(\"文件名\", self.img_paths[index], \"\\t标签值\", self.labels[index])\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#训练数据加载 \n",
    "train_dataset = FoodDataset(data_path='data/',mode='train')\n",
    "train_loader = paddle.io.DataLoader(train_dataset, batch_size=train_parameters['train_batch_size'], shuffle=True)\n",
    "#测试数据加载 \n",
    "eval_dataset = FoodDataset(data_path='data/',mode='eval')\n",
    "eval_loader = paddle.io.DataLoader(eval_dataset, batch_size = 8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.__len__())\r\n",
    "print(eval_dataset.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **二、模型配置**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#定义卷积网络\r\n",
    "class MyCNN(nn.Layer): \r\n",
    "    def __init__(self):\r\n",
    "        super(MyCNN,self).__init__()\r\n",
    "        # in_channels, out_channels, kernel_size, stride=1, padding=0\r\n",
    "        self.conv0 = nn.Conv2D(in_channels = 3,out_channels=64, kernel_size=3,padding=0,stride=1)\r\n",
    "        self.pool0 = nn.MaxPool2D(kernel_size = 2,stride = 2)\r\n",
    "        self.conv1 = nn.Conv2D(in_channels = 64,out_channels=128,kernel_size=3,padding=0, stride = 1)\r\n",
    "        self.pool1 = nn.MaxPool2D(kernel_size = 2, stride = 2)\r\n",
    "        self.conv2 = nn.Conv2D(in_channels = 128,out_channels=128,kernel_size=5,padding=0)\r\n",
    "        self.pool2 = nn.MaxPool2D(kernel_size = 2, stride = 2)\r\n",
    "        self.fc1 = nn.Linear(in_features=128*5*5,out_features=5)\r\n",
    "\r\n",
    "    def forward(self,input): \r\n",
    "        x = self.conv0(input)\r\n",
    "        x = self.pool0(x)\r\n",
    "        x = self.conv1(x)\r\n",
    "        x = self.pool1(x)\r\n",
    "        x = self.conv2(x)\r\n",
    "        x = self.pool2(x)\r\n",
    "        x = fluid.layers.reshape(x,shape=[-1,128*5*5])\r\n",
    "        y = self.fc1(x)\r\n",
    " \r\n",
    "        return y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      " Layer (type)       Input Shape          Output Shape         Param #    \n",
      "===========================================================================\n",
      "   Conv2D-43      [[1, 3, 64, 64]]     [1, 64, 62, 62]         1,792     \n",
      " MaxPool2D-43    [[1, 64, 62, 62]]     [1, 64, 31, 31]           0       \n",
      "   Conv2D-44     [[1, 64, 31, 31]]     [1, 128, 29, 29]       73,856     \n",
      " MaxPool2D-44    [[1, 128, 29, 29]]    [1, 128, 14, 14]          0       \n",
      "   Conv2D-45     [[1, 128, 14, 14]]    [1, 128, 10, 10]       409,728    \n",
      " MaxPool2D-45    [[1, 128, 10, 10]]     [1, 128, 5, 5]           0       \n",
      "   Linear-15        [[1, 3200]]             [1, 5]            16,005     \n",
      "===========================================================================\n",
      "Total params: 501,381\n",
      "Trainable params: 501,381\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 3.48\n",
      "Params size (MB): 1.91\n",
      "Estimated Total Size (MB): 5.44\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "{'total_params': 501381, 'trainable_params': 501381}\n"
     ]
    }
   ],
   "source": [
    "# 实例化网络\r\n",
    "model = MyCNN()\r\n",
    "# 定义输入\r\n",
    "input_define = paddle.static.InputSpec(shape=[-1, 3 , 64, 64],\r\n",
    "                                   dtype=\"float32\",\r\n",
    "                                   name=\"img\")\r\n",
    "\r\n",
    "label_define = paddle.static.InputSpec(shape=[-1, 1],\r\n",
    "                                       dtype=\"int64\",\r\n",
    "                                       name=\"label\")\r\n",
    "model = paddle.Model(model, inputs=input_define, labels=label_define)\r\n",
    "params_info = model.summary((1,3,64,64))\r\n",
    "print(params_info) # 打印模型基础结构和参数信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **三、模型训练 && 四、模型评估**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Batch=0\n",
    "Batchs=[]\n",
    "all_train_accs=[]\n",
    "def draw_train_acc(Batchs, train_accs):\n",
    "    title=\"training accs\"\n",
    "    plt.title(title, fontsize=24)\n",
    "    plt.xlabel(\"batch\", fontsize=14)\n",
    "    plt.ylabel(\"acc\", fontsize=14)\n",
    "    plt.plot(Batchs, train_accs, color='green', label='training accs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "all_train_loss=[]\n",
    "def draw_train_loss(Batchs, train_loss):\n",
    "    title=\"training loss\"\n",
    "    plt.title(title, fontsize=24)\n",
    "    plt.xlabel(\"batch\", fontsize=14)\n",
    "    plt.ylabel(\"loss\", fontsize=14)\n",
    "    plt.plot(Batchs, train_loss, color='red', label='training loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0,step:10,train_loss:1.8661689758300781,train_acc:0.21875\n",
      "epoch:0,step:20,train_loss:1.698227047920227,train_acc:0.296875\n"
     ]
    }
   ],
   "source": [
    "model=MyCNN() # 模型实例化\n",
    "model.train() # 训练模式\n",
    "cross_entropy = paddle.nn.CrossEntropyLoss()\n",
    "opt=paddle.optimizer.SGD(learning_rate=0.001, parameters=model.parameters())\n",
    "\n",
    "epochs_num=train_parameters['num_epochs'] #迭代次数\n",
    "for pass_num in range(train_parameters['num_epochs']):\n",
    "    for batch_id,data in enumerate(train_loader()):\n",
    "        image = data[0]\n",
    "        label = data[1]\n",
    "        predict=model(image) #数据传入model\n",
    "        # print(predict)\n",
    "        # print(np.argmax(predict,axis=1))\n",
    "        loss=cross_entropy(predict,label)\n",
    "        acc=paddle.metric.accuracy(predict,label.reshape([-1,1]))#计算精度\n",
    "        # acc = np.mean(label==np.argmax(predict,axis=1))\n",
    "        \n",
    "        if batch_id!=0 and batch_id%10==0:\n",
    "            Batch = Batch+10\n",
    "            Batchs.append(Batch)\n",
    "            all_train_loss.append(loss.numpy()[0])\n",
    "            all_train_accs.append(acc.numpy()[0]) \n",
    "            print(\"epoch:{},step:{},train_loss:{},train_acc:{}\".format(pass_num,batch_id,loss.numpy()[0],acc.numpy()[0]))        \n",
    "        loss.backward()       \n",
    "        opt.step()\n",
    "        opt.clear_grad()   #opt.clear_grad()来重置梯度\n",
    "paddle.save(model.state_dict(),'MyCNN')#保存模型\n",
    "draw_train_acc(Batchs,all_train_accs)\n",
    "draw_train_loss(Batchs,all_train_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **五、模型评估**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#模型评估\n",
    "para_state_dict = paddle.load(\"MyCNN\") \n",
    "model = MyCNN()\n",
    "model.set_state_dict(para_state_dict) #加载模型参数\n",
    "model.eval() #验证模式\n",
    "\n",
    "accs = []\n",
    "\n",
    "for batch_id,data in enumerate(eval_loader()):#测试集\n",
    "    image=data[0]\n",
    "    label=data[1]     \n",
    "    predict=model(image)       \n",
    "    acc=paddle.metric.accuracy(predict,label)\n",
    "    accs.append(acc.numpy()[0])\n",
    "    avg_acc = np.mean(accs)\n",
    "print(\"当前模型在验证集上的准确率为:\",avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def unzip_infer_data(src_path,target_path):\n",
    "    '''\n",
    "    解压预测数据集\n",
    "    '''\n",
    "    if(not os.path.isdir(target_path)):     \n",
    "        z = zipfile.ZipFile(src_path, 'r')\n",
    "        z.extractall(path=target_path)\n",
    "        z.close()\n",
    "\n",
    "\n",
    "def load_image(img_path):\n",
    "    '''\n",
    "    预测图片预处理\n",
    "    '''\n",
    "    img = Image.open(img_path) \n",
    "    if img.mode != 'RGB': \n",
    "        img = img.convert('RGB') \n",
    "    img = img.resize((64, 64), Image.BILINEAR)\n",
    "    img = np.array(img).astype('float32') \n",
    "    img = img.transpose((2, 0, 1))  # HWC to CHW \n",
    "    img = img/255                # 像素值归一化 \n",
    "    return img\n",
    "\n",
    "\n",
    "infer_src_path = '/home/aistudio/data/data42610/foods.zip'\n",
    "infer_dst_path = '/home/aistudio/data/foods_test'\n",
    "unzip_infer_data(infer_src_path,infer_dst_path)\n",
    "\n",
    "'''\n",
    "模型预测\n",
    "'''\n",
    "\n",
    "para_state_dict = paddle.load(\"MyCNN\")\n",
    "model = MyCNN()\n",
    "model.set_state_dict(para_state_dict) #加载模型参数\n",
    "model.eval() #验证模式\n",
    "\n",
    "#展示预测图片\n",
    "infer_path='data/foods/baklava/1936599.jpg'\n",
    "img = Image.open(infer_path)\n",
    "plt.imshow(img)          #根据数组绘制图像\n",
    "plt.show()               #显示图像\n",
    "#对预测图片进行预处理\n",
    "infer_imgs = []\n",
    "infer_imgs.append(load_image(infer_path))\n",
    "infer_imgs = np.array(infer_imgs)\n",
    "label_dic = train_parameters['label_dict']\n",
    "for i in range(len(infer_imgs)):\n",
    "    data = infer_imgs[i]\n",
    "    dy_x_data = np.array(data).astype('float32')\n",
    "    dy_x_data=dy_x_data[np.newaxis,:, : ,:]\n",
    "    img = paddle.to_tensor (dy_x_data)\n",
    "    out = model(img)\n",
    "    lab = np.argmax(out.numpy())  #argmax():返回最大数的索引\n",
    "    print(\"第{}个样本,被预测为：{},真实标签为：{}\".format(i+1,label_dic[str(lab)],infer_path.split('/')[-2]) )     \n",
    "print(\"结束\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
